{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36589d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model response (code-only expected) ===\n",
      " ```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.model_selection import KFold\n",
      "from sklearn.ensemble import HistGradientBoostingRegressor\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from sklearn.multioutput import MultiOutputRegressor\n",
      "\n",
      "# Define targets and features\n",
      "TARGETS = [\"formation_energy_ev_natom\", \"bandgap_energy_ev\"]\n",
      "FEATURES = [\n",
      "    \"spacegroup\",\n",
      "    \"number_of_total_atoms\",\n",
      "    \"percent_atom_al\",\n",
      "    \"percent_atom_ga\",\n",
      "    \"percent_atom_in\",\n",
      "    \"lattice_vector_1_ang\",\n",
      "    \"lattice_vector_2_ang\",\n",
      "    \"lattice_vector_3_ang\",\n",
      "    \"lattice_angle_alpha_degree\",\n",
      "    \"lattice_angle_beta_degree\",\n",
      "    \"lattice_angle_gamma_degree\",\n",
      "]\n",
      "ALL_COLUMNS = [\"id\"] + FEATURES + TARGETS\n",
      "\n",
      "# --- Input Validation ---\n",
      "try:\n",
      "    train_df = pd.read_csv(\"train.csv\")\n",
      "    test_df = pd.read_csv(\"test.csv\")\n",
      "except FileNotFoundError as e:\n",
      "    print(f\"Error: {e}. Make sure train.csv and test.csv are in the same directory.\")\n",
      "    exit(1)\n",
      "\n",
      "for col in ALL_COLUMNS:\n",
      "    if col not in train_df.columns:\n",
      "        print(f\"Error: Missing expected column '{col}' in train.csv.\")\n",
      "        exit(1)\n",
      "\n",
      "for col in FEATURES + [\"id\"]:\n",
      "    if col not in test_df.columns:\n",
      "        print(f\"Error: Missing expected column '{col}' in test.csv.\")\n",
      "        exit(1)\n",
      "\n",
      "\n",
      "# --- Feature Engineering (Simple) ---\n",
      "# Add interaction terms or polynomial features if needed.\n",
      "# For now, stick to provided features to keep it fast and simple.\n",
      "X_train = train_df[FEATURES]\n",
      "y_train = train_df[TARGETS]\n",
      "X_test = test_df[FEATURES]\n",
      "test_ids = test_df[\"id\"]\n",
      "\n",
      "# --- Target Transformation ---\n",
      "# Apply log1p to targets for RMSLE calculation and model training\n",
      "y_train_transformed = np.log1p(y_train)\n",
      "\n",
      "# --- Model ---\n",
      "# Using HistGradientBoostingRegressor for speed and efficiency\n",
      "# Wrap it with MultiOutputRegressor to handle multiple targets\n",
      "model = MultiOutputRegressor(\n",
      "    HistGradientBoostingRegressor(random_state=42, max_iter=500, learning_rate=0.05)\n",
      ")\n",
      "\n",
      "# --- Cross-Validation ---\n",
      "NFOLDS = 5\n",
      "kf = KFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n",
      "rmsle_scores = []\n",
      "\n",
      "print(\"Starting Cross-Validation...\")\n",
      "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train_transformed)):\n",
      "    X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
      "    y_train_fold, y_val_fold = y_train_transformed.iloc[train_idx], y_train_transformed.iloc[val_idx]\n",
      "\n",
      "    model.fit(X_train_fold, y_train_fold)\n",
      "\n",
      "    y_pred_fold_transformed = model.predict(X_val_fold)\n",
      "\n",
      "    # Inverse transform predictions for RMSLE calculation\n",
      "    y_pred_fold = np.expm1(y_pred_fold_transformed)\n",
      "    y_pred_fold = np.maximum(0, y_pred_fold)  # Clip predictions to be non-negative\n",
      "\n",
      "    # Calculate RMSLE for each target\n",
      "    for i, target in enumerate(TARGETS):\n",
      "        rmsle_fold = np.sqrt(mean_squared_error(y_val_fold.iloc[:, i], y_pred_fold_transformed[:, i]))\n",
      "        if i == 0:\n",
      "            rmsle_scores.append({\"fold\": fold, \"target\": target, \"rmsle\": rmsle_fold})\n",
      "        else:\n",
      "            rmsle_scores.append({\"fold\": fold, \"target\": target, \"rmsle\": rmsle_fold})\n",
      "\n",
      "print(\"-\" * 30)\n",
      "rmsle_df = pd.DataFrame(rmsle_scores)\n",
      "for target in TARGETS:\n",
      "    print(f\"CV RMSLE for {target}: {rmsle_df[rmsle_df['target'] == target]['rmsle'].mean():.4f}\")\n",
      "print(\"-\" * 30)\n",
      "print(f\"Overall Mean CV RMSLE: {rmsle_df['rmsle'].mean():.4f}\")\n",
      "print(\"-\" * 30)\n",
      "\n",
      "\n",
      "# --- Final Training and Prediction ---\n",
      "print(\"Training on full data...\")\n",
      "model.fit(X_train, y_train_transformed)\n",
      "\n",
      "print(\"Making predictions on test data...\")\n",
      "y_pred_test_transformed = model.predict(X_test)\n",
      "\n",
      "# Inverse transform predictions and clip to non-negative\n",
      "y_pred_test = np.expm1(y_pred_test_transformed)\n",
      "y_pred_test = np.maximum(0, y_pred_test)\n",
      "\n",
      "# --- Submission ---\n",
      "submission_df = pd.DataFrame({\"id\": test_ids})\n",
      "for i, target in enumerate(TARGETS):\n",
      "    submission_df[target] = y_pred_test[:, i]\n",
      "\n",
      "# Ensure columns are in the correct order\n",
      "submission_df = submission_df[[\"id\"] + TARGETS]\n",
      "\n",
      "print(\"\\nSubmission Head:\")\n",
      "print(submission_df.head())\n",
      "\n",
      "submission_df.to_csv(\"submission.csv\", index=False)\n",
      "print(\"\\nSubmission saved to submission.csv\")\n",
      "\n",
      "```\n",
      "\n",
      "=== Execution result ===\n",
      " {\n",
      "  \"ok\": true,\n",
      "  \"stdout\": \"Starting Cross-Validation...\\n------------------------------\\nCV RMSLE for formation_energy_ev_natom: 0.0355\\nCV RMSLE for bandgap_energy_ev: 0.0976\\n------------------------------\\nOverall Mean CV RMSLE: 0.0666\\n------------------------------\\nTraining on full data...\\nMaking predictions on test data...\\n\\nSubmission Head:\\n   id  formation_energy_ev_natom  bandgap_energy_ev\\n0   1                   0.203843           1.625094\\n1   2                   0.056843           3.686147\\n2   3                   0.147712           3.597159\\n3   4                   0.026147           3.021155\\n4   5                   0.134945           1.609126\\n\\nSubmission saved to submission.csv\\nExecution time: a minute seconds (time limit is 5 minutes).\",\n",
      "  \"stderr\": \"\",\n",
      "  \"returncode\": 0,\n",
      "  \"exec_time\": 79.17405271530151,\n",
      "  \"exc_type\": null,\n",
      "  \"exc_info\": null,\n",
      "  \"exc_stack\": null\n",
      "}\n",
      "\n",
      "Submission written to: /Users/ayushpatel/Desktop/startup/ascent/.agent_workspace/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# simple_agent_runner.py\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- External helpers (your files) ---\n",
    "from interpreter import Interpreter  # uses ExecutionResult dataclass internally\n",
    "from response import extract_code\n",
    "\n",
    "# ---------- OpenRouter-compatible OpenAI client ----------\n",
    "MODEL = os.getenv(\"OPENROUTER_MODEL\", \"google/gemini-2.5-flash-lite\")\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": os.getenv(\"SITE_URL\", \"\"),\n",
    "        \"X-Title\": os.getenv(\"APP_NAME\", \"My App\"),\n",
    "    } or None,\n",
    ")\n",
    "\n",
    "# ---------- Workspace ----------\n",
    "WORK_DIR = Path(os.getenv(\"AGENT_WORKDIR\", \".agent_workspace\")).resolve()\n",
    "WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Interpreter bridge ----------\n",
    "def _run_with_interpreter(code: str, timeout_sec: int = 180) -> dict:\n",
    "    \"\"\"\n",
    "    Execute code in an isolated interpreter process and return a dict:\n",
    "        {\n",
    "            \"ok\": bool,\n",
    "            \"stdout\": str,\n",
    "            \"stderr\": str,\n",
    "            \"returncode\": int,\n",
    "            \"exec_time\": float,\n",
    "            \"exc_type\": Optional[str],\n",
    "            \"exc_info\": Optional[dict],\n",
    "            \"exc_stack\": Optional[list[tuple]],\n",
    "        }\n",
    "    \"\"\"\n",
    "    interp = Interpreter(\n",
    "        working_dir=WORK_DIR,\n",
    "        timeout=timeout_sec,\n",
    "        format_tb_ipython=False,\n",
    "        agent_file_name=\"run_kaggle_tc.py\",\n",
    "    )\n",
    "    result = interp.run(code, reset_session=True)\n",
    "    joined = \"\".join(result.term_out)\n",
    "    ok = result.exc_type is None\n",
    "    out = {\n",
    "        \"ok\": ok,\n",
    "        \"stdout\": joined if ok else \"\",\n",
    "        \"stderr\": \"\" if ok else joined,\n",
    "        \"returncode\": 0 if ok else 1,\n",
    "        \"exec_time\": result.exec_time,\n",
    "        \"exc_type\": result.exc_type,\n",
    "        \"exc_info\": result.exc_info,\n",
    "        \"exc_stack\": result.exc_stack,\n",
    "    }\n",
    "    interp.cleanup_session()\n",
    "    return out\n",
    "\n",
    "def run_from_agent_output(text: str, timeout_sec: int = 180) -> dict:\n",
    "    code = (extract_code(text) or \"\").strip()\n",
    "    if not code:\n",
    "        raise RuntimeError(\"No valid Python code found in agent output.\")\n",
    "    return _run_with_interpreter(code, timeout_sec=timeout_sec)\n",
    "\n",
    "def ask_and_run(prompt: str, system_msg: str, timeout_sec: int = 180) -> dict:\n",
    "    \"\"\"\n",
    "    Ask the model for Python code (only a fenced block), then execute it.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    resp = client.chat.completions.create(model=MODEL, messages=messages)\n",
    "    text = resp.choices[0].message.content or \"\"\n",
    "    code = (extract_code(text) or \"\").strip()\n",
    "    if not code:\n",
    "        raise RuntimeError(\"Model response did not contain a valid Python code block.\")\n",
    "    result = _run_with_interpreter(code, timeout_sec=timeout_sec)\n",
    "    return {\"response_text\": text, \"code\": code, \"result\": result}\n",
    "\n",
    "# ---------- Strong guardrailed system message ----------\n",
    "KAGGLE_TC_SYSTEM = \"\"\"\n",
    "You are an expert ML engineer. Return ONLY a Python fenced block (```python ... ```).\n",
    "The code must be self-contained, safe, and runnable in a local, offline environment.\n",
    "\n",
    "Hard requirements:\n",
    "- Use only local files. NO network calls or package installs.\n",
    "- Assume the working directory contains train.csv and test.csv.\n",
    "- Use Python 3.10+, numpy, pandas, and scikit-learn (prefer builtins; may try lightgbm/xgboost).\n",
    "- Must finish quickly (≤ ~2-3 minutes on CPU).\n",
    "- Print: dataset shapes, basic feature summary, CV RMSLE for each target and their mean.\n",
    "- Write a valid Kaggle submission to ./submission.csv with columns:\n",
    "  [\"id\",\"formation_energy_ev_natom\",\"bandgap_energy_ev\"].\n",
    "- Avoid randomness: set seeds for reproducibility.\n",
    "- Don’t rely on seaborn or plotting; print text metrics instead.\n",
    "- Don't use any try-except blocks let errors crash the program.\n",
    "\"\"\"\n",
    "\n",
    "# ---------- Task prompt describing the competition and exact deliverables ----------\n",
    "KAGGLE_TC_PROMPT = f\"\"\"\n",
    "Create a single Python script that:\n",
    "1) Reads Kaggle 'Predicting Transparent Conductors' data from the current directory:\n",
    "   - train.csv (has targets formation_energy_ev_natom, bandgap_energy_ev)\n",
    "   - test.csv (no targets)\n",
    "\n",
    "2) Builds a fast feature pipeline using only CSV columns.\n",
    "   - Csv columns: id,spacegroup,number_of_total_atoms,percent_atom_al,percent_atom_ga,percent_atom_in,lattice_vector_1_ang,lattice_vector_2_ang,lattice_vector_3_ang,lattice_angle_alpha_degree,lattice_angle_beta_degree,lattice_angle_gamma_degree,formation_energy_ev_natom,bandgap_energy_ev.\n",
    "\n",
    "3) Targets and evaluation:\n",
    "   - Targets: [\"formation_energy_ev_natom\",\"bandgap_energy_ev\"]\n",
    "   - Use RMSLE (natural log) per target with log1p transform.\n",
    "   - Train either two separate regressors or a MultiOutputRegressor.\n",
    "   - Do KFold CV (e.g., 5 folds) reporting RMSLE per target and mean RMSLE.\n",
    "\n",
    "4) Models:\n",
    "   - Prefer scikit-learn CPU-friendly models that train fast (HistGradientBoostingRegressor, GradientBoostingRegressor, RandomForestRegressor).\n",
    "   - Optionally try LightGBM/XGBoost.\n",
    "   - Use sensible hyperparams (early stopping if available).\n",
    "   - Fit on full training data after CV, predict on test, inverse-transform with expm1, and clip to non-negative.\n",
    "\n",
    "5) Output:\n",
    "   - Save submission to ./submission.csv with EXACT header:\n",
    "       id,formation_energy_ev_natom,bandgap_energy_ev\n",
    "   - Print the head() of the submission as a quick sanity check.\n",
    "\n",
    "6) Robustness:\n",
    "   - If any expected column is missing, print a clear message and exit gracefully.\n",
    "\n",
    "Remember: Keep it simple, fast, and deterministic; no external downloads or plotting. Ensure the script exits 0 on success.\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    # Default: Kaggle Transparent Conductors\n",
    "    out = ask_and_run(KAGGLE_TC_PROMPT, KAGGLE_TC_SYSTEM, timeout_sec=300)\n",
    "    print(\"\\n=== Model response (code-only expected) ===\\n\", out[\"response_text\"])\n",
    "    print(\"\\n=== Execution result ===\\n\", json.dumps(out[\"result\"], indent=2))\n",
    "\n",
    "    # Convenience: show where submission should be\n",
    "    sub_path = WORK_DIR / \"submission.csv\"\n",
    "    if sub_path.exists():\n",
    "        print(f\"\\nSubmission written to: {sub_path}\")\n",
    "    else:\n",
    "        print(\"\\nNo submission.csv found. Check stderr above for errors.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6845bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81320486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e4432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a24d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781dce57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3253146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MVP Orchestrator Summary ===\n",
      "Timestamp (UTC): 2025-08-19T18:04:40.117770+00:00\n",
      "Status         : success\n",
      "Code hash      : 538405befe83\n",
      "Exec time (s)  : 15.16\n",
      "CV RMSLE       : fe=0.027293328328806266, bg=0.05324380258395238, mean=0.04026856545637932\n",
      "Submission     : FOUND -> /Users/ayushpatel/Desktop/startup/ascent/.agent_workspace/submission.csv\n",
      "Registry       : /Users/ayushpatel/Desktop/startup/ascent/.agent_workspace/registry.jsonl\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "MVP: one-orchestrator + one-dev-agent that solves a Kaggle task end-to-end.\n",
    "\n",
    "Dependencies:\n",
    "- Your existing `interpreter.py` and `response.py` modules (from the prompt).\n",
    "- Env: OPENROUTER_API_KEY (or supply a model/key however you already do).\n",
    "\n",
    "What it does:\n",
    "1) Prompts the dev agent (LLM) for a single Python script.\n",
    "2) Runs that script in a jailed Interpreter workspace.\n",
    "3) Expects:\n",
    "     - ./submission.csv  (required)\n",
    "     - ./metrics.json    (requested, but will try to parse stdout if missing)\n",
    "4) Appends a compact run record to .agent_workspace/registry.jsonl\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- Local helpers you already have ---\n",
    "from interpreter import Interpreter  # uses ExecutionResult dataclass internally\n",
    "from response import extract_code\n",
    "\n",
    "# ---------- Config ----------\n",
    "MODEL = os.getenv(\"OPENROUTER_MODEL\", \"google/gemini-2.5-flash-lite\")\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": os.getenv(\"SITE_URL\", \"\"),\n",
    "        \"X-Title\": os.getenv(\"APP_NAME\", \"Kaggle-MVP\"),\n",
    "    } or None,\n",
    ")\n",
    "\n",
    "WORK_DIR = Path(os.getenv(\"AGENT_WORKDIR\", \".agent_workspace\")).resolve()\n",
    "WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "REGISTRY = WORK_DIR / \"registry.jsonl\"  # append-only run log\n",
    "SUBMISSION = WORK_DIR / \"submission.csv\"\n",
    "METRICS_JSON = WORK_DIR / \"metrics.json\"\n",
    "\n",
    "\n",
    "# ---------- Minimal \"dev agent\" contract ----------\n",
    "SYSTEM_MSG = \"\"\"\n",
    "You are an expert ML engineer. Return ONLY a Python fenced block (```python ... ```).\n",
    "The code must be self-contained, offline, and runnable fast on CPU.\n",
    "\n",
    "Hard requirements:\n",
    "- Use ONLY local files. NO network calls, NO package installs.\n",
    "- Assume the CWD contains train.csv and test.csv for Kaggle \"Predicting Transparent Conductors\".\n",
    "- Use Python 3.10+, numpy, pandas, and scikit-learn (prefer builtins; may try lightgbm/xgboost if present).\n",
    "- Total runtime ≲ 2–3 minutes CPU.\n",
    "- Deterministic: set seeds; avoid randomness where possible.\n",
    "- No plotting or seaborn. Print concise textual metrics.\n",
    "\n",
    "Data/columns:\n",
    "- train.csv columns include:\n",
    "  id, spacegroup, number_of_total_atoms, percent_atom_al, percent_atom_ga, percent_atom_in,\n",
    "  lattice_vector_1_ang, lattice_vector_2_ang, lattice_vector_3_ang,\n",
    "  lattice_angle_alpha_degree, lattice_angle_beta_degree, lattice_angle_gamma_degree,\n",
    "  formation_energy_ev_natom, bandgap_energy_ev\n",
    "- test.csv is the same but without the two targets.\n",
    "\n",
    "Targets and evaluation:\n",
    "- Targets: [\"formation_energy_ev_natom\", \"bandgap_energy_ev\"].\n",
    "- Use KFold CV (e.g., 5 folds). For scoring, use RMSLE with log1p on y during training/validation,\n",
    "  and report RMSLE per target plus the mean RMSLE across targets.\n",
    "\n",
    "Modeling:\n",
    "- Prefer fast, CPU-friendly models (e.g., HistGradientBoostingRegressor, RandomForestRegressor,\n",
    "  GradientBoostingRegressor). You may wrap separate models with MultiOutputRegressor or train two models.\n",
    "- After CV, fit on full training data, predict on test, inverse with expm1, clip negatives to 0.\n",
    "\n",
    "Outputs (MUST):\n",
    "1) Save ./submission.csv with EXACT header:\n",
    "   id,formation_energy_ev_natom,bandgap_energy_ev\n",
    "2) Print: dataset shapes and CV RMSLE per target and mean RMSLE.\n",
    "3) ALSO write ./metrics.json with schema:\n",
    "   {\n",
    "     \"cv_rmsle\": {\n",
    "       \"formation_energy_ev_natom\": <float>,\n",
    "       \"bandgap_energy_ev\": <float>,\n",
    "       \"mean\": <float>\n",
    "     },\n",
    "     \"n_train\": <int>,\n",
    "     \"n_test\": <int>,\n",
    "     \"model\": \"<brief model description>\"\n",
    "   }\n",
    "\n",
    "Robustness:\n",
    "- If any expected column is missing, print a clear message and exit with an error (no try/except that hides tracebacks).\n",
    "- Avoid external state. Use a fixed random_state everywhere it applies.\n",
    "- Keep imports standard; avoid seaborn/matplotlib.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = \"\"\"\n",
    "Write ONE Python script that satisfies the contract above.\n",
    "Be explicit and simple:\n",
    "- Build a minimal preprocessing/encoding for numeric/categorical features that appear in the CSVs.\n",
    "- Use 5-fold KFold (shuffle=True, random_state=42).\n",
    "- For RMSLE, use log1p(y) during training/CV and compute RMSLE on predictions via expm1(...) carefully.\n",
    "- Print CV RMSLE per target and mean RMSLE.\n",
    "- Save metrics.json exactly as specified.\n",
    "- Save submission.csv with header: id,formation_energy_ev_natom,bandgap_energy_ev\n",
    "- Print the head() of the submission for sanity.\n",
    "\n",
    "Return ONLY a Python fenced block.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ---------- Orchestrator helpers ----------\n",
    "def _run_with_interpreter(code: str, timeout_sec: int = 300) -> Dict[str, Any]:\n",
    "    \"\"\"Execute a Python script inside the jailed interpreter and return a structured result.\"\"\"\n",
    "    interp = Interpreter(\n",
    "        working_dir=WORK_DIR,\n",
    "        timeout=timeout_sec,\n",
    "        format_tb_ipython=False,\n",
    "        agent_file_name=\"run_kaggle_tc.py\",\n",
    "    )\n",
    "    result = interp.run(code, reset_session=True)\n",
    "    joined = \"\".join(result.term_out)\n",
    "    ok = result.exc_type is None\n",
    "    out = {\n",
    "        \"ok\": ok,\n",
    "        \"stdout\": joined if ok else \"\",\n",
    "        \"stderr\": \"\" if ok else joined,\n",
    "        \"returncode\": 0 if ok else 1,\n",
    "        \"exec_time\": result.exec_time,\n",
    "        \"exc_type\": result.exc_type,\n",
    "        \"exc_info\": result.exc_info,\n",
    "        \"exc_stack\": result.exc_stack,\n",
    "    }\n",
    "    interp.cleanup_session()\n",
    "    return out\n",
    "\n",
    "\n",
    "def _ask_dev_agent(system_msg: str, prompt: str) -> Dict[str, str]:\n",
    "    \"\"\"Ask the model for code (just one fenced block) and return {'response_text','code'}.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg.strip()},\n",
    "        {\"role\": \"user\", \"content\": prompt.strip()},\n",
    "    ]\n",
    "    resp = client.chat.completions.create(model=MODEL, messages=messages)\n",
    "    text = (resp.choices[0].message.content or \"\").strip()\n",
    "    code = (extract_code(text) or \"\").strip()\n",
    "    if not code:\n",
    "        raise RuntimeError(\"Model response did not contain a valid Python fenced code block.\")\n",
    "    return {\"response_text\": text, \"code\": code}\n",
    "\n",
    "\n",
    "def _short_hash(s: str) -> str:\n",
    "    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()[:12]\n",
    "\n",
    "\n",
    "def _read_metrics() -> Optional[Dict[str, Any]]:\n",
    "    if METRICS_JSON.exists():\n",
    "        try:\n",
    "            return json.loads(METRICS_JSON.read_text())\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def _parse_stdout_metrics(stdout: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Very loose parser as a fallback if metrics.json is missing.\n",
    "    Looks for lines that mention RMSLE and extracts floats.\n",
    "    \"\"\"\n",
    "    lines = stdout.splitlines()\n",
    "    floats = [float(x) for x in re.findall(r\"(?<![A-Za-z])(\\d+\\.\\d+)\", stdout)]\n",
    "    # Heuristic: last 3 floats might be [fe_rmsle, bg_rmsle, mean]\n",
    "    if len(floats) >= 3:\n",
    "        fe, bg, mean = floats[-3], floats[-2], floats[-1]\n",
    "        return {\n",
    "            \"cv_rmsle\": {\n",
    "                \"formation_energy_ev_natom\": fe,\n",
    "                \"bandgap_energy_ev\": bg,\n",
    "                \"mean\": mean,\n",
    "            }\n",
    "        }\n",
    "    return None\n",
    "\n",
    "\n",
    "def _append_registry(entry: Dict[str, Any]) -> None:\n",
    "    with REGISTRY.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def orchestrate_once(timeout_sec: int = 300) -> None:\n",
    "    # 1) Dev agent proposes code\n",
    "    agent_out = _ask_dev_agent(SYSTEM_MSG, USER_PROMPT)\n",
    "    code = agent_out[\"code\"]\n",
    "    code_hash = _short_hash(code)\n",
    "\n",
    "    # 2) Execute in sandbox\n",
    "    exec_result = _run_with_interpreter(code, timeout_sec=timeout_sec)\n",
    "\n",
    "    # 3) Evaluate artifacts\n",
    "    submission_ok = SUBMISSION.exists()\n",
    "    metrics = _read_metrics()\n",
    "    if not metrics:\n",
    "        metrics = _parse_stdout_metrics(exec_result[\"stdout\"])\n",
    "\n",
    "    status = \"success\" if exec_result[\"ok\"] and submission_ok else \"failure\"\n",
    "\n",
    "    # 4) Write to registry.jsonl\n",
    "    now = datetime.now(timezone.utc).isoformat()\n",
    "    entry = {\n",
    "        \"ts_utc\": now,\n",
    "        \"status\": status,\n",
    "        \"model\": MODEL,\n",
    "        \"code_hash\": code_hash,\n",
    "        \"exec_time_sec\": exec_result[\"exec_time\"],\n",
    "        \"returncode\": exec_result[\"returncode\"],\n",
    "        \"exc_type\": exec_result[\"exc_type\"],\n",
    "        \"metrics\": metrics,\n",
    "        \"submission_path\": str(SUBMISSION) if submission_ok else None,\n",
    "        \"stdout_tail\": exec_result[\"stdout\"][-2000:],\n",
    "        \"stderr_tail\": exec_result[\"stderr\"][-2000:],\n",
    "    }\n",
    "    _append_registry(entry)\n",
    "\n",
    "    # 5) Print concise summary to console\n",
    "    print(\"\\n=== MVP Orchestrator Summary ===\")\n",
    "    print(f\"Timestamp (UTC): {now}\")\n",
    "    print(f\"Status         : {status}\")\n",
    "    print(f\"Code hash      : {code_hash}\")\n",
    "    print(f\"Exec time (s)  : {exec_result['exec_time']:.2f}\")\n",
    "    if metrics and \"cv_rmsle\" in metrics:\n",
    "        cr = metrics[\"cv_rmsle\"]\n",
    "        print(\n",
    "            f\"CV RMSLE       : fe={cr.get('formation_energy_ev_natom')}, \"\n",
    "            f\"bg={cr.get('bandgap_energy_ev')}, mean={cr.get('mean')}\"\n",
    "        )\n",
    "    print(f\"Submission     : {'FOUND' if submission_ok else 'MISSING'} -> {SUBMISSION}\")\n",
    "    print(f\"Registry       : {REGISTRY}\")\n",
    "    if not exec_result[\"ok\"]:\n",
    "        print(\"\\n--- ERROR OUTPUT (tail) ---\")\n",
    "        print(entry[\"stderr_tail\"] or entry[\"stdout_tail\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        orchestrate_once(timeout_sec=300)\n",
    "    except Exception as e:\n",
    "        print(f\"[FATAL] Orchestrator error: {e}\", file=sys.stderr)\n",
    "        sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24ab77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
