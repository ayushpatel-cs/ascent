{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3253146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MVP Orchestrator Summary ===\n",
      "Timestamp (UTC): 2025-08-19T18:04:40.117770+00:00\n",
      "Status         : success\n",
      "Code hash      : 538405befe83\n",
      "Exec time (s)  : 15.16\n",
      "CV RMSLE       : fe=0.027293328328806266, bg=0.05324380258395238, mean=0.04026856545637932\n",
      "Submission     : FOUND -> /Users/ayushpatel/Desktop/startup/ascent/.agent_workspace/submission.csv\n",
      "Registry       : /Users/ayushpatel/Desktop/startup/ascent/.agent_workspace/registry.jsonl\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "MVP: one-orchestrator + one-dev-agent that solves a Kaggle task end-to-end.\n",
    "\n",
    "Dependencies:\n",
    "- Your existing `interpreter.py` and `response.py` modules (from the prompt).\n",
    "- Env: OPENROUTER_API_KEY (or supply a model/key however you already do).\n",
    "\n",
    "What it does:\n",
    "1) Prompts the dev agent (LLM) for a single Python script.\n",
    "2) Runs that script in a jailed Interpreter workspace.\n",
    "3) Expects:\n",
    "     - ./submission.csv  (required)\n",
    "     - ./metrics.json    (requested, but will try to parse stdout if missing)\n",
    "4) Appends a compact run record to .agent_workspace/registry.jsonl\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- Local helpers you already have ---\n",
    "from interpreter import Interpreter  # uses ExecutionResult dataclass internally\n",
    "from response import extract_code\n",
    "\n",
    "# ---------- Config ----------\n",
    "MODEL = os.getenv(\"OPENROUTER_MODEL\", \"google/gemini-2.5-flash-lite\")\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": os.getenv(\"SITE_URL\", \"\"),\n",
    "        \"X-Title\": os.getenv(\"APP_NAME\", \"Kaggle-MVP\"),\n",
    "    } or None,\n",
    ")\n",
    "\n",
    "WORK_DIR = Path(os.getenv(\"AGENT_WORKDIR\", \".agent_workspace\")).resolve()\n",
    "WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "REGISTRY = WORK_DIR / \"registry.jsonl\"  # append-only run log\n",
    "SUBMISSION = WORK_DIR / \"submission.csv\"\n",
    "METRICS_JSON = WORK_DIR / \"metrics.json\"\n",
    "\n",
    "\n",
    "# ---------- Minimal \"dev agent\" contract ----------\n",
    "SYSTEM_MSG = \"\"\"\n",
    "You are an expert ML engineer. Return ONLY a Python fenced block (```python ... ```).\n",
    "The code must be self-contained, offline, and runnable fast on CPU.\n",
    "\n",
    "Hard requirements:\n",
    "- Use ONLY local files. NO network calls, NO package installs.\n",
    "- Assume the CWD contains train.csv and test.csv for Kaggle \"Predicting Transparent Conductors\".\n",
    "- Use Python 3.10+, numpy, pandas, and scikit-learn (prefer builtins; may try lightgbm/xgboost if present).\n",
    "- Total runtime ≲ 2–3 minutes CPU.\n",
    "- Deterministic: set seeds; avoid randomness where possible.\n",
    "- No plotting or seaborn. Print concise textual metrics.\n",
    "\n",
    "Data/columns:\n",
    "- train.csv columns include:\n",
    "  id, spacegroup, number_of_total_atoms, percent_atom_al, percent_atom_ga, percent_atom_in,\n",
    "  lattice_vector_1_ang, lattice_vector_2_ang, lattice_vector_3_ang,\n",
    "  lattice_angle_alpha_degree, lattice_angle_beta_degree, lattice_angle_gamma_degree,\n",
    "  formation_energy_ev_natom, bandgap_energy_ev\n",
    "- test.csv is the same but without the two targets.\n",
    "\n",
    "Targets and evaluation:\n",
    "- Targets: [\"formation_energy_ev_natom\", \"bandgap_energy_ev\"].\n",
    "- Use KFold CV (e.g., 5 folds). For scoring, use RMSLE with log1p on y during training/validation,\n",
    "  and report RMSLE per target plus the mean RMSLE across targets.\n",
    "\n",
    "Modeling:\n",
    "- Prefer fast, CPU-friendly models (e.g., HistGradientBoostingRegressor, RandomForestRegressor,\n",
    "  GradientBoostingRegressor). You may wrap separate models with MultiOutputRegressor or train two models.\n",
    "- After CV, fit on full training data, predict on test, inverse with expm1, clip negatives to 0.\n",
    "\n",
    "Outputs (MUST):\n",
    "1) Save ./submission.csv with EXACT header:\n",
    "   id,formation_energy_ev_natom,bandgap_energy_ev\n",
    "2) Print: dataset shapes and CV RMSLE per target and mean RMSLE.\n",
    "3) ALSO write ./metrics.json with schema:\n",
    "   {\n",
    "     \"cv_rmsle\": {\n",
    "       \"formation_energy_ev_natom\": <float>,\n",
    "       \"bandgap_energy_ev\": <float>,\n",
    "       \"mean\": <float>\n",
    "     },\n",
    "     \"n_train\": <int>,\n",
    "     \"n_test\": <int>,\n",
    "     \"model\": \"<brief model description>\"\n",
    "   }\n",
    "\n",
    "Robustness:\n",
    "- If any expected column is missing, print a clear message and exit with an error (no try/except that hides tracebacks).\n",
    "- Avoid external state. Use a fixed random_state everywhere it applies.\n",
    "- Keep imports standard; avoid seaborn/matplotlib.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = \"\"\"\n",
    "Write ONE Python script that satisfies the contract above.\n",
    "Be explicit and simple:\n",
    "- Build a minimal preprocessing/encoding for numeric/categorical features that appear in the CSVs.\n",
    "- Use 5-fold KFold (shuffle=True, random_state=42).\n",
    "- For RMSLE, use log1p(y) during training/CV and compute RMSLE on predictions via expm1(...) carefully.\n",
    "- Print CV RMSLE per target and mean RMSLE.\n",
    "- Save metrics.json exactly as specified.\n",
    "- Save submission.csv with header: id,formation_energy_ev_natom,bandgap_energy_ev\n",
    "- Print the head() of the submission for sanity.\n",
    "\n",
    "Return ONLY a Python fenced block.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ---------- Orchestrator helpers ----------\n",
    "def _run_with_interpreter(code: str, timeout_sec: int = 300) -> Dict[str, Any]:\n",
    "    \"\"\"Execute a Python script inside the jailed interpreter and return a structured result.\"\"\"\n",
    "    interp = Interpreter(\n",
    "        working_dir=WORK_DIR,\n",
    "        timeout=timeout_sec,\n",
    "        format_tb_ipython=False,\n",
    "        agent_file_name=\"run_kaggle_tc.py\",\n",
    "    )\n",
    "    result = interp.run(code, reset_session=True)\n",
    "    joined = \"\".join(result.term_out)\n",
    "    ok = result.exc_type is None\n",
    "    out = {\n",
    "        \"ok\": ok,\n",
    "        \"stdout\": joined if ok else \"\",\n",
    "        \"stderr\": \"\" if ok else joined,\n",
    "        \"returncode\": 0 if ok else 1,\n",
    "        \"exec_time\": result.exec_time,\n",
    "        \"exc_type\": result.exc_type,\n",
    "        \"exc_info\": result.exc_info,\n",
    "        \"exc_stack\": result.exc_stack,\n",
    "    }\n",
    "    interp.cleanup_session()\n",
    "    return out\n",
    "\n",
    "\n",
    "def _ask_dev_agent(system_msg: str, prompt: str) -> Dict[str, str]:\n",
    "    \"\"\"Ask the model for code (just one fenced block) and return {'response_text','code'}.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg.strip()},\n",
    "        {\"role\": \"user\", \"content\": prompt.strip()},\n",
    "    ]\n",
    "    resp = client.chat.completions.create(model=MODEL, messages=messages)\n",
    "    text = (resp.choices[0].message.content or \"\").strip()\n",
    "    code = (extract_code(text) or \"\").strip()\n",
    "    if not code:\n",
    "        raise RuntimeError(\"Model response did not contain a valid Python fenced code block.\")\n",
    "    return {\"response_text\": text, \"code\": code}\n",
    "\n",
    "\n",
    "def _short_hash(s: str) -> str:\n",
    "    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()[:12]\n",
    "\n",
    "\n",
    "def _read_metrics() -> Optional[Dict[str, Any]]:\n",
    "    if METRICS_JSON.exists():\n",
    "        try:\n",
    "            return json.loads(METRICS_JSON.read_text())\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def _parse_stdout_metrics(stdout: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Very loose parser as a fallback if metrics.json is missing.\n",
    "    Looks for lines that mention RMSLE and extracts floats.\n",
    "    \"\"\"\n",
    "    lines = stdout.splitlines()\n",
    "    floats = [float(x) for x in re.findall(r\"(?<![A-Za-z])(\\d+\\.\\d+)\", stdout)]\n",
    "    # Heuristic: last 3 floats might be [fe_rmsle, bg_rmsle, mean]\n",
    "    if len(floats) >= 3:\n",
    "        fe, bg, mean = floats[-3], floats[-2], floats[-1]\n",
    "        return {\n",
    "            \"cv_rmsle\": {\n",
    "                \"formation_energy_ev_natom\": fe,\n",
    "                \"bandgap_energy_ev\": bg,\n",
    "                \"mean\": mean,\n",
    "            }\n",
    "        }\n",
    "    return None\n",
    "\n",
    "\n",
    "def _append_registry(entry: Dict[str, Any]) -> None:\n",
    "    with REGISTRY.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def orchestrate_once(timeout_sec: int = 300) -> None:\n",
    "    # 1) Dev agent proposes code\n",
    "    agent_out = _ask_dev_agent(SYSTEM_MSG, USER_PROMPT)\n",
    "    code = agent_out[\"code\"]\n",
    "    code_hash = _short_hash(code)\n",
    "\n",
    "    # 2) Execute in sandbox\n",
    "    exec_result = _run_with_interpreter(code, timeout_sec=timeout_sec)\n",
    "\n",
    "    # 3) Evaluate artifacts\n",
    "    submission_ok = SUBMISSION.exists()\n",
    "    metrics = _read_metrics()\n",
    "    if not metrics:\n",
    "        metrics = _parse_stdout_metrics(exec_result[\"stdout\"])\n",
    "\n",
    "    status = \"success\" if exec_result[\"ok\"] and submission_ok else \"failure\"\n",
    "\n",
    "    # 4) Write to registry.jsonl\n",
    "    now = datetime.now(timezone.utc).isoformat()\n",
    "    entry = {\n",
    "        \"ts_utc\": now,\n",
    "        \"status\": status,\n",
    "        \"model\": MODEL,\n",
    "        \"code_hash\": code_hash,\n",
    "        \"exec_time_sec\": exec_result[\"exec_time\"],\n",
    "        \"returncode\": exec_result[\"returncode\"],\n",
    "        \"exc_type\": exec_result[\"exc_type\"],\n",
    "        \"metrics\": metrics,\n",
    "        \"submission_path\": str(SUBMISSION) if submission_ok else None,\n",
    "        \"stdout_tail\": exec_result[\"stdout\"][-2000:],\n",
    "        \"stderr_tail\": exec_result[\"stderr\"][-2000:],\n",
    "    }\n",
    "    _append_registry(entry)\n",
    "\n",
    "    # 5) Print concise summary to console\n",
    "    print(\"\\n=== MVP Orchestrator Summary ===\")\n",
    "    print(f\"Timestamp (UTC): {now}\")\n",
    "    print(f\"Status         : {status}\")\n",
    "    print(f\"Code hash      : {code_hash}\")\n",
    "    print(f\"Exec time (s)  : {exec_result['exec_time']:.2f}\")\n",
    "    if metrics and \"cv_rmsle\" in metrics:\n",
    "        cr = metrics[\"cv_rmsle\"]\n",
    "        print(\n",
    "            f\"CV RMSLE       : fe={cr.get('formation_energy_ev_natom')}, \"\n",
    "            f\"bg={cr.get('bandgap_energy_ev')}, mean={cr.get('mean')}\"\n",
    "        )\n",
    "    print(f\"Submission     : {'FOUND' if submission_ok else 'MISSING'} -> {SUBMISSION}\")\n",
    "    print(f\"Registry       : {REGISTRY}\")\n",
    "    if not exec_result[\"ok\"]:\n",
    "        print(\"\\n--- ERROR OUTPUT (tail) ---\")\n",
    "        print(entry[\"stderr_tail\"] or entry[\"stdout_tail\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        orchestrate_once(timeout_sec=300)\n",
    "    except Exception as e:\n",
    "        print(f\"[FATAL] Orchestrator error: {e}\", file=sys.stderr)\n",
    "        sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24ab77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
